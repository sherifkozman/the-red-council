# ===========================================
# The Red Council - Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# ===========================================
# Google Cloud / Vertex AI (Required)
# ===========================================
# Your GCP project ID with Vertex AI enabled
GOOGLE_CLOUD_PROJECT=your-project-id

# Vertex AI location for Llama models
GOOGLE_CLOUD_LOCATION=us-central1

# ===========================================
# Gemini API (Alternative to Vertex AI)
# ===========================================
# If using Gemini API directly instead of Vertex AI
# GOOGLE_API_KEY=your-gemini-api-key

# ===========================================
# Model Configuration (Optional)
# ===========================================
# Override default model providers
# RC_ATTACKER__PROVIDER=vertex_llama_default
# RC_TARGET__PROVIDER=gemini_default
# RC_JUDGE__PROVIDER=gemini_default
# RC_DEFENDER__PROVIDER=gemini_default

# ===========================================
# Application Settings (Optional)
# ===========================================
# API server host and port
# API_HOST=0.0.0.0
# API_PORT=8000

# Frontend URL (for CORS)
# FRONTEND_URL=http://localhost:3000

# ===========================================
# Development Settings (Optional)
# ===========================================
# Enable mock mode for testing without API calls
# RC_MOCK_MODE=true

# Log level (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO
