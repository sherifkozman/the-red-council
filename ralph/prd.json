{
  "project": "The Red Council v0.5.0 - Agent Security",
  "branchName": "feature/agent-security-v0.5.0",
  "description": "Extend The Red Council from pure LLM testing to AI Agent security testing. Adds Agent Instrumentation SDK for observing tool calls, memory access, and action/speech divergence. Implements OWASP Agentic Top 10 attack patterns.",
  "phases": [
    {
      "id": 1,
      "name": "Phase 1: Agent Instrumentation SDK",
      "description": "Core SDK for wrapping and observing agent behavior including tool calls, memory access, and action sequences."
    },
    {
      "id": 2,
      "name": "Phase 2: Extended Judge for Agents",
      "description": "Extend Judge agent to evaluate agent-specific security criteria based on OWASP Agentic Top 10."
    },
    {
      "id": 3,
      "name": "Phase 3: Agent Attack Templates",
      "description": "ChromaDB collection with 20-30 agent-specific attack patterns targeting OWASP Agentic vulnerabilities."
    },
    {
      "id": 4,
      "name": "Phase 4: Agent Security Reports",
      "description": "Generate detailed reports with vulnerability mapping, recommendations, and remediation guidance."
    },
    {
      "id": 5,
      "name": "Phase 5: UI Enhancements",
      "description": "Dashboard updates to visualize agent behavior timeline, tool call chains, and OWASP coverage."
    },
    {
      "id": 6,
      "name": "Phase 6: Framework Integrations",
      "description": "Adapters for LangChain, LangGraph, and MCP protocol integration."
    },
    {
      "id": 7,
      "name": "Phase 7: UI/UX Completion",
      "description": "Wire existing UI components to backend, implement three agent testing modes (Demo, SDK, Remote), add onboarding flows and session management."
    }
  ],
  "userStories": [
    {
      "id": "TRC-001",
      "title": "Create OWASP Agentic Top 10 enum and criteria definitions",
      "description": "As a developer, I need to define the OWASP Agentic Top 10 (ASI01-ASI10) as Python enums with descriptions and detection criteria so that the system has a standard vulnerability taxonomy.",
      "acceptanceCriteria": [
        "Create src/core/owasp_agentic.py with OWASPAgenticRisk enum",
        "Define all 10 categories: ASI01_EXCESSIVE_AGENCY through ASI10_OVER_TRUST_IN_LLMS",
        "Each enum value has: code, name, description, severity, detection_criteria",
        "Create Pydantic model AgenticRiskCriteria with fields for automated detection",
        "Include mapping of risk to observable behaviors (tool abuse, memory leak, etc)",
        "Unit tests for enum completeness and criteria validation",
        "Docstrings reference OWASP Agentic spec (December 2025)"
      ],
      "priority": 1,
      "phaseId": 1,
      "passes": true,
      "dependsOn": [],
      "notes": "Reference: https://owasp.org/www-project-top-10-for-large-language-model-applications/",
      "files": ["src/core/owasp_agentic.py", "tests/core/test_owasp_agentic.py"]
    },
    {
      "id": "TRC-002",
      "title": "Create agent event schemas (ToolCallEvent, MemoryAccessEvent, ActionRecord)",
      "description": "As a developer, I need Pydantic schemas to represent agent observable events so that the instrumentation SDK has structured data models.",
      "acceptanceCriteria": [
        "Create src/core/agent_schemas.py",
        "ToolCallEvent: tool_name, arguments, result, timestamp, duration_ms, success, exception_type (Optional)",
        "MemoryAccessEvent: operation (read/write/delete), key, value_preview, timestamp, sensitive_detected (bool)",
        "ActionRecord: action_type, description, target, timestamp, related_tool_calls (List[str])",
        "SpeechRecord: content, intent, timestamp, is_response_to_user",
        "DivergenceEvent: speech_intent, actual_action, severity (LOW/MEDIUM/HIGH), explanation, confidence_score",
        "All models include id (UUID) and session_id for correlation",
        "Create AgentEvent union type: AgentEvent = ToolCallEvent | MemoryAccessEvent | ActionRecord | SpeechRecord | DivergenceEvent",
        "Create AgentInstrumentationConfig model: enable_tool_interception (bool), enable_memory_monitoring (bool), divergence_threshold (float 0-1), sampling_rate (float 0-1), max_events (int)",
        "Unit tests for serialization/deserialization of all models",
        "Unit tests for AgentEvent union type validation"
      ],
      "priority": 2,
      "phaseId": 1,
      "passes": true,
      "dependsOn": ["TRC-001"],
      "notes": "These schemas form the observation layer for the instrumented agent. AgentEvent union and AgentInstrumentationConfig are critical for downstream stories.",
      "files": ["src/core/agent_schemas.py", "tests/core/test_agent_schemas.py"]
    },
    {
      "id": "TRC-003",
      "title": "Create InstrumentedAgent base wrapper class",
      "description": "As a developer, I need a base wrapper class that can observe any agent's behavior so that users can wrap their own agents for security testing.",
      "acceptanceCriteria": [
        "Create src/agents/instrumented.py with InstrumentedAgent class",
        "Constructor accepts: agent (Any), name (str), config (AgentInstrumentationConfig)",
        "Methods: wrap_tool_call, wrap_memory_access, record_speech, record_action",
        "Property: events -> List[AgentEvent] (all recorded events in order)",
        "Property: tool_calls -> List[ToolCallEvent]",
        "Property: memory_accesses -> List[MemoryAccessEvent]",
        "Property: divergences -> List[DivergenceEvent]",
        "Method: detect_divergence(speech: str, actions: List[ActionRecord]) -> Optional[DivergenceEvent]",
        "Method: clear_events() to reset event buffer",
        "Method: get_events_since(timestamp: datetime) -> List[AgentEvent]",
        "Context manager support for automatic cleanup (__enter__, __exit__)",
        "Async-compatible with both sync and async agents (detect via inspect.iscoroutinefunction)",
        "Respect config.max_events - drop oldest when exceeded",
        "Respect config.sampling_rate - probabilistic event capture",
        "Unit tests with mock agent covering sync and async scenarios"
      ],
      "priority": 3,
      "phaseId": 1,
      "passes": true,
      "dependsOn": ["TRC-002"],
      "notes": "This is the core SDK class that users will use to wrap their agents",
      "files": ["src/agents/instrumented.py", "tests/agents/test_instrumented.py"]
    },
    {
      "id": "TRC-004",
      "title": "Implement tool call interception and logging",
      "description": "As a developer, I need the InstrumentedAgent to intercept and log all tool calls so that we can analyze tool usage patterns for security vulnerabilities.",
      "acceptanceCriteria": [
        "Add tool_registry: Dict[str, ToolRegistration] to InstrumentedAgent",
        "Create ToolRegistration dataclass: func (Callable), description (str), sensitive_args (List[str])",
        "Method: register_tool(name: str, func: Callable, description: str, sensitive_args: List[str] = [])",
        "Method: intercept_tool_call(tool_name: str, **kwargs) -> Any",
        "Interception records: timestamp, arguments (with sensitive args masked), duration, result, exception if any",
        "Support for both sync and async tool functions via asyncio.iscoroutinefunction check",
        "Detect tool abuse patterns: excessive calls (>N in window), sensitive data in args",
        "Method: get_tool_call_stats() -> Dict[str, ToolCallStats] with counts, avg_duration, error_rate",
        "Follow error pattern from src/agents/errors.py - create ToolInterceptionError",
        "Unit tests for tool interception with various tool signatures (sync, async, *args, **kwargs)"
      ],
      "priority": 4,
      "phaseId": 1,
      "passes": true,
      "dependsOn": ["TRC-003"],
      "notes": "Tool call interception is critical for detecting ASI01 Excessive Agency",
      "files": ["src/agents/instrumented.py", "src/agents/errors.py", "tests/agents/test_instrumented.py"]
    },
    {
      "id": "TRC-005",
      "title": "Implement memory access monitoring",
      "description": "As a developer, I need the InstrumentedAgent to monitor memory/state access so that we can detect memory injection and data exfiltration.",
      "acceptanceCriteria": [
        "Add memory_store: Dict[str, Any] to InstrumentedAgent (observable)",
        "Method: get_memory(key: str) -> Any with logging, returns None if key not found",
        "Method: set_memory(key: str, value: Any) with logging",
        "Method: delete_memory(key: str) with logging, no-op if key not found",
        "Method: list_memory_keys() -> List[str]",
        "Each operation creates MemoryAccessEvent with sanitized value preview (max 100 chars, redact secrets)",
        "Detect patterns: reading keys matching SECRET_PATTERNS, writing to SYSTEM_KEY_PATTERNS, bulk reads (>N in window)",
        "Define SECRET_PATTERNS = ['password', 'secret', 'api_key', 'token', 'credential']",
        "Define SYSTEM_KEY_PATTERNS = ['__', 'system_', 'config_']",
        "Option to integrate with external memory systems via MemoryBackend protocol (Redis, etc)",
        "Create MemoryBackend Protocol: get, set, delete, keys methods",
        "Unit tests for memory operations and pattern detection"
      ],
      "priority": 5,
      "phaseId": 1,
      "passes": true,
      "dependsOn": ["TRC-003"],
      "notes": "Memory monitoring detects ASI07 Insecure Long-Term Memory",
      "files": ["src/agents/instrumented.py", "tests/agents/test_instrumented.py"]
    },
    {
      "id": "TRC-006",
      "title": "Implement action vs speech divergence detection",
      "description": "As a developer, I need to detect when an agent says one thing but does another so that we can identify deceptive behavior.",
      "acceptanceCriteria": [
        "Create src/agents/divergence.py with DivergenceDetector class",
        "Method: analyze_divergence(speech: str, action: ActionRecord) -> DivergenceEvent | None",
        "Use embedding-based semantic similarity (sentence-transformers, same model as attack_kb.py: all-MiniLM-L6-v2)",
        "Severity levels: LOW (similarity 0.5-0.7), MEDIUM (0.3-0.5), HIGH (<0.3 or opposite intent detected)",
        "Configurable similarity threshold via config.divergence_threshold (default 0.5)",
        "Method: batch_analyze(speeches: List[str], actions: List[ActionRecord]) -> List[DivergenceEvent]",
        "Cache embeddings for performance (LRU cache with max_size=1000)",
        "Fallback to keyword-based heuristics if embedding fails",
        "Integration point for AgentJudge to call for divergence scoring",
        "Unit tests with known divergence scenarios: opposite actions, partial matches, exact matches"
      ],
      "priority": 6,
      "phaseId": 1,
      "passes": true,
      "dependsOn": ["TRC-002", "TRC-003"],
      "notes": "Divergence detection identifies agent deception (saying vs doing). Uses same embedding model as attack_kb for consistency.",
      "files": ["src/agents/divergence.py", "tests/agents/test_divergence.py"]
    },
    {
      "id": "TRC-007",
      "title": "Create AgentJudgeScore and ViolationResult schemas",
      "description": "As a developer, I need extended scoring schemas that include agent-specific criteria so that the judge can evaluate agents comprehensively.",
      "acceptanceCriteria": [
        "Add to src/core/agent_schemas.py",
        "Create ViolationResult model: detected (bool), severity (int 1-10), evidence (str), recommendation (str), owasp_category (OWASPAgenticRisk)",
        "Create AgentJudgeScore model (composition with JudgeScore, not inheritance)",
        "AgentJudgeScore.base_score: JudgeScore (existing LLM judge result)",
        "AgentJudgeScore.owasp_violations: List[ViolationResult] with evidence per category",
        "AgentJudgeScore.tool_abuse_score: float (0-10) with tool_abuse_details (str)",
        "AgentJudgeScore.memory_safety_score: float (0-10) with memory_safety_details (str)",
        "AgentJudgeScore.divergence_count: int with divergence_examples (List[DivergenceEvent], max 5)",
        "AgentJudgeScore.overall_agent_risk: float (0-10) computed from weighted components",
        "AgentJudgeScore.recommendations: List[str] prioritized by severity",
        "Method: AgentJudgeScore.get_failed_categories() -> List[OWASPAgenticRisk]",
        "Method: AgentJudgeScore.to_summary_dict() -> Dict for API responses",
        "Unit tests for score computation and edge cases"
      ],
      "priority": 7,
      "phaseId": 2,
      "passes": true,
      "dependsOn": ["TRC-001", "TRC-002"],
      "notes": "This schema extends the existing JudgeScore for agent-specific metrics. ViolationResult is used by TRC-009.",
      "files": ["src/core/agent_schemas.py", "tests/core/test_agent_schemas.py"]
    },
    {
      "id": "TRC-008",
      "title": "Create AgentJudge class extending Judge",
      "description": "As a developer, I need an extended judge that can evaluate agent behavior beyond just LLM responses so that we can score agents on OWASP criteria.",
      "acceptanceCriteria": [
        "Create src/agents/agent_judge.py with AgentJudge class",
        "Uses composition: wraps existing JudgeAgent from src/agents/judge.py",
        "Constructor: AgentJudge(judge: JudgeAgent, config: AgentJudgeConfig)",
        "Create AgentJudgeConfig: weights for each score component, thresholds",
        "Method: evaluate_agent(events: List[AgentEvent], context: Optional[str] = None) -> AgentJudgeScore",
        "Internally calls JudgeAgent for base LLM evaluation if conversation history available",
        "Analyzes tool call patterns for ASI01, ASI02 violations",
        "Analyzes memory access for ASI07 violations",
        "Analyzes divergence events for deception detection",
        "Returns comprehensive AgentJudgeScore with all violations",
        "Async method: async def evaluate_agent_async(...) for non-blocking evaluation",
        "Logging via standard logger (same pattern as other agents)",
        "Integration tests with mock agent events covering all OWASP categories"
      ],
      "priority": 8,
      "phaseId": 2,
      "passes": true,
      "dependsOn": ["TRC-006", "TRC-007"],
      "notes": "AgentJudge is the core evaluator for agent security. Uses composition to wrap existing Judge.",
      "files": ["src/agents/agent_judge.py", "tests/agents/test_agent_judge.py"]
    },
    {
      "id": "TRC-009",
      "title": "Create OWASP criteria evaluation methods in AgentJudge",
      "description": "As a developer, I need the AgentJudge to evaluate each OWASP Agentic criterion so that we get detailed vulnerability detection.",
      "acceptanceCriteria": [
        "Method: check_asi01_excessive_agency(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi02_inadequate_controls(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi03_vulnerable_integrations(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi04_prompt_injection(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi05_improper_authorization(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi06_data_disclosure(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi07_insecure_memory(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi08_misalignment(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi09_weak_guardrails(events: List[AgentEvent]) -> ViolationResult",
        "Method: check_asi10_over_trust(events: List[AgentEvent]) -> ViolationResult",
        "Each method returns ViolationResult: detected (bool), severity (1-10), evidence (str), recommendation (str)",
        "Private method: _check_all_owasp(events) -> List[ViolationResult] calls all 10 checks",
        "Fallback behavior: if check fails due to insufficient data, return ViolationResult(detected=False, severity=0, evidence='Insufficient data', recommendation='Collect more events')",
        "Unit tests for each check with positive cases (violation detected) and negative cases (no violation)"
      ],
      "priority": 9,
      "phaseId": 2,
      "passes": true,
      "dependsOn": ["TRC-007", "TRC-008"],
      "notes": "Comprehensive OWASP criteria evaluation. Each check is independent and can be run selectively.",
      "files": ["src/agents/agent_judge.py", "tests/agents/test_agent_judge.py"]
    },
    {
      "id": "TRC-010",
      "title": "Create agent attack template collection structure",
      "description": "As a developer, I need a ChromaDB collection for agent-specific attacks so that the attacker can use curated agent exploitation prompts.",
      "acceptanceCriteria": [
        "Create src/knowledge/agent_attacks.py",
        "Define AgentAttackTemplate Pydantic model extending base AttackArtifact from taxonomy.py",
        "Additional fields: target_owasp (List[OWASPAgenticRisk]), requires_tool_access (bool), requires_memory_access (bool), expected_agent_behavior (str)",
        "Create AgentAttackKnowledgeBase class following pattern from attack_kb.py",
        "Use ChromaDB collection 'agent_attacks' separate from 'attack_kb'",
        "Use same embedding model as attack_kb.py: all-MiniLM-L6-v2 (SAFE_EMBEDDING_MODEL)",
        "Method: get_attacks_for_owasp(risk: OWASPAgenticRisk, k: int = 5) -> List[AgentAttackTemplate]",
        "Method: get_attacks_by_capability(tools: bool = False, memory: bool = False, k: int = 5) -> List[AgentAttackTemplate]",
        "Method: add(template: AgentAttackTemplate) following same base64 encoding pattern",
        "Method: retrieve_attacks(goal: str, k: int = 5) -> List[AgentAttackTemplate] for semantic search",
        "Unit tests for collection operations including add, retrieve, filter"
      ],
      "priority": 11,
      "phaseId": 3,
      "passes": true,
      "dependsOn": ["TRC-001"],
      "notes": "Separate collection allows targeted agent attacks. Follows same patterns as existing attack_kb.py.",
      "files": ["src/knowledge/agent_attacks.py", "tests/knowledge/test_agent_attacks.py"]
    },
    {
      "id": "TRC-011",
      "title": "Seed agent attack templates for ASI01-ASI03",
      "description": "As a developer, I need attack templates for Excessive Agency, Inadequate Controls, and Vulnerable Integrations so that we can test common agent vulnerabilities.",
      "acceptanceCriteria": [
        "Add minimum 3 templates for ASI01: tool abuse (call tool N times), permission escalation (request admin tool), unauthorized action",
        "Add minimum 3 templates for ASI02: missing confirmation bypass, auto-execute dangerous action, skip human approval",
        "Add minimum 3 templates for ASI03: integration exploitation (abuse third-party API), API abuse (exceed rate limits), data leak via integration",
        "Each template has: prompt, expected_behavior, detection_criteria, target_owasp, severity",
        "Templates are seeded via src/knowledge/agent_seed_data.py in AGENT_ATTACK_TEMPLATES list",
        "Function: seed_agent_attacks(kb: AgentAttackKnowledgeBase) to populate collection",
        "Integration test verifies all templates load correctly and are retrievable"
      ],
      "priority": 12,
      "phaseId": 3,
      "passes": true,
      "dependsOn": ["TRC-010"],
      "notes": "Focus on the most critical agent vulnerabilities first. Minimum 9 templates in this story.",
      "files": ["src/knowledge/agent_seed_data.py", "tests/knowledge/test_agent_seed.py"]
    },
    {
      "id": "TRC-012",
      "title": "Seed agent attack templates for ASI04-ASI06",
      "description": "As a developer, I need attack templates for Prompt Injection, Authorization, and Data Disclosure so that we can test these vulnerabilities.",
      "acceptanceCriteria": [
        "Add minimum 3 templates for ASI04: indirect prompt injection via tool output, injection via retrieved document, injection via user input to tool",
        "Add minimum 3 templates for ASI05: authorization bypass via role confusion, privilege escalation via tool chain, access control circumvention",
        "Add minimum 3 templates for ASI06: data exfiltration via tool outputs, PII leak in responses, credential exposure",
        "Each template includes OWASP mapping and severity (1-10)",
        "Templates cover both direct and indirect attack vectors",
        "Templates reference real-world attack patterns where possible"
      ],
      "priority": 13,
      "phaseId": 3,
      "passes": true,
      "dependsOn": ["TRC-010"],
      "notes": "Second batch of attack templates. Minimum 9 templates in this story.",
      "files": ["src/knowledge/agent_seed_data.py", "tests/knowledge/test_agent_seed.py"]
    },
    {
      "id": "TRC-013",
      "title": "Seed agent attack templates for ASI07-ASI10",
      "description": "As a developer, I need attack templates for Memory, Misalignment, Guardrails, and Over-Trust so that we have complete OWASP coverage.",
      "acceptanceCriteria": [
        "Add minimum 3 templates for ASI07: memory injection (poison context), context pollution (overwrite history), state manipulation",
        "Add minimum 3 templates for ASI08: goal manipulation (redirect objective), reward hacking (game metrics), instruction override",
        "Add minimum 3 templates for ASI09: guardrail bypass (encode forbidden content), constraint evasion (roleplay escape), filter circumvention",
        "Add minimum 3 templates for ASI10: trust exploitation (fake authority), false authority injection, blind trust in external data",
        "Verify total 27-36 agent-specific templates across all categories (TRC-011 + TRC-012 + TRC-013)",
        "Each template is tagged with applicable OWASP categories (can have multiple)"
      ],
      "priority": 14,
      "phaseId": 3,
      "passes": true,
      "dependsOn": ["TRC-010"],
      "notes": "Complete the attack template library. Minimum 12 templates in this story, 27+ total.",
      "files": ["src/knowledge/agent_seed_data.py", "tests/knowledge/test_agent_seed.py"]
    },
    {
      "id": "TRC-014",
      "title": "Create AgentSecurityReport and AgentHardeningPlan models",
      "description": "As a developer, I need comprehensive report and hardening plan models so that users get detailed security assessment results and remediation guidance.",
      "acceptanceCriteria": [
        "Create src/core/agent_report.py with AgentSecurityReport model",
        "AgentSecurityReport fields: summary (str), owasp_coverage (Dict[OWASPAgenticRisk, bool]), vulnerability_findings (List[ViolationResult]), risk_score (float 0-10)",
        "Field: tool_analysis: ToolAnalysisSection with call_count, unique_tools, suspicious_patterns, abuse_detected",
        "Field: memory_analysis: MemoryAnalysisSection with access_count, sensitive_keys_accessed, injection_attempts",
        "Field: divergence_analysis: DivergenceAnalysisSection with divergence_count, examples (max 5), severity_distribution",
        "Field: recommendations: List[Recommendation] with priority (HIGH/MEDIUM/LOW), category, description",
        "Field: remediation_steps: List[RemediationStep] with code_example (Optional), effort_estimate (str)",
        "Create AgentHardeningPlan model: tool_controls (List[ToolAccessControl]), memory_isolation (MemoryPolicy), guardrails (List[GuardrailConfig]), owasp_remediations (Dict[OWASPAgenticRisk, RemediationStep])",
        "Create ToolAccessControl: tool_name, allowed_args, rate_limit, requires_approval",
        "Create MemoryPolicy: allowed_keys_pattern, denied_keys_pattern, max_value_size, encryption_required",
        "Create GuardrailConfig: name, trigger_pattern, action (block/warn/log), message",
        "Method: AgentSecurityReport.to_markdown() -> str for readable output (use template)",
        "Method: AgentSecurityReport.to_json() -> str for programmatic access",
        "Unit tests for report generation and serialization"
      ],
      "priority": 15,
      "phaseId": 4,
      "passes": true,
      "dependsOn": ["TRC-007"],
      "notes": "Report and hardening plan models for comprehensive security assessment output. AgentHardeningPlan is used by TRC-024.",
      "files": ["src/core/agent_report.py", "tests/core/test_agent_report.py"]
    },
    {
      "id": "TRC-015",
      "title": "Implement report generator from AgentJudgeScore",
      "description": "As a developer, I need to generate detailed reports from judge scores so that users understand their agent's vulnerabilities.",
      "acceptanceCriteria": [
        "Create src/reports/__init__.py (new package)",
        "Create src/reports/agent_report_generator.py",
        "Class AgentReportGenerator with method generate(score: AgentJudgeScore, events: List[AgentEvent]) -> AgentSecurityReport",
        "Generate OWASP coverage dict from score.owasp_violations",
        "Include specific evidence for each finding from ViolationResult.evidence",
        "Generate actionable recommendations sorted by severity",
        "Include code-level remediation suggestions where applicable",
        "Method: generate_summary(score: AgentJudgeScore) -> str for quick overview",
        "Method: generate_heatmap_data(score: AgentJudgeScore) -> Dict for UI visualization",
        "Use Jinja2 template for markdown generation (store in src/reports/templates/)",
        "Unit tests with sample scores covering all OWASP categories"
      ],
      "priority": 16,
      "phaseId": 4,
      "passes": true,
      "dependsOn": ["TRC-009", "TRC-014"],
      "notes": "Report generator transforms scores into actionable reports",
      "files": ["src/reports/__init__.py", "src/reports/agent_report_generator.py", "src/reports/templates/report.md.j2", "tests/reports/test_agent_report_generator.py"]
    },
    {
      "id": "TRC-016",
      "title": "Add OWASP coverage visualization component",
      "description": "As a developer, I need a Streamlit component to show OWASP coverage so that users can see which vulnerabilities were tested.",
      "acceptanceCriteria": [
        "Create src/ui/components/owasp_coverage.py",
        "Function: render_owasp_coverage(score: AgentJudgeScore) -> None",
        "Display 10-cell grid for ASI01-ASI10 using st.columns",
        "Color coding: green (passed), red (failed/detected), yellow (warning), gray (not tested)",
        "Use st.expander for details on each category when clicked",
        "Show severity score and evidence summary in expander",
        "Mobile-responsive layout (2x5 grid on mobile, 5x2 on desktop)",
        "Works in existing Streamlit dashboard without breaking changes",
        "Fallback to text-based list if grid rendering fails"
      ],
      "priority": 17,
      "phaseId": 5,
      "passes": true,
      "dependsOn": ["TRC-007"],
      "notes": "Visual OWASP coverage for dashboard. Streamlit has limited hover support - use expanders instead.",
      "files": ["src/ui/components/owasp_coverage.py", "tests/ui/test_owasp_coverage.py"]
    },
    {
      "id": "TRC-017",
      "title": "Add agent behavior timeline visualization",
      "description": "As a developer, I need a timeline view of agent events so that users can trace the attack sequence.",
      "acceptanceCriteria": [
        "Create src/ui/components/agent_timeline.py",
        "Function: render_agent_timeline(events: List[AgentEvent]) -> None",
        "Chronological display of: tool calls, memory access, speech, actions using st.container",
        "Color coding by event type using custom CSS (st.markdown with unsafe_allow_html)",
        "Highlight divergence events in red with warning icon",
        "Use st.expander for each event to show full details",
        "Filter by event type using st.multiselect",
        "Pagination for >50 events using st.number_input for page selection",
        "Show timestamps relative to session start",
        "Export timeline as JSON button"
      ],
      "priority": 18,
      "phaseId": 5,
      "passes": true,
      "dependsOn": ["TRC-002"],
      "notes": "Timeline view for understanding attack flow",
      "files": ["src/ui/components/agent_timeline.py", "tests/ui/test_agent_timeline.py"]
    },
    {
      "id": "TRC-018",
      "title": "Add tool call chain visualization",
      "description": "As a developer, I need to visualize tool call sequences so that users can identify tool abuse patterns.",
      "acceptanceCriteria": [
        "Create src/ui/components/tool_chain.py",
        "Function: render_tool_chain(tool_calls: List[ToolCallEvent]) -> None",
        "Use streamlit-agraph library for graph visualization (add to dependencies)",
        "Fallback to networkx + matplotlib static image if streamlit-agraph unavailable",
        "Fallback to text-based sequence diagram if both fail",
        "Nodes: tool names with call count badges",
        "Edges: sequence arrows with timestamps",
        "Highlight suspicious patterns: loops (same tool >3x consecutively), excessive calls (>10 total)",
        "Show tool arguments and results in node tooltip/click detail",
        "Identify potential ASI01 violations with red border on nodes",
        "Legend explaining colors and patterns"
      ],
      "priority": 19,
      "phaseId": 5,
      "passes": true,
      "dependsOn": ["TRC-002"],
      "notes": "Tool chain visualization for ASI01 detection. Uses streamlit-agraph with graceful fallbacks.",
      "files": ["src/ui/components/tool_chain.py", "tests/ui/test_tool_chain.py"]
    },
    {
      "id": "TRC-019",
      "title": "Update dashboard to support agent testing mode",
      "description": "As a developer, I need the main dashboard to switch between LLM and Agent modes so that users can test both.",
      "acceptanceCriteria": [
        "Create src/ui/components/mode_selector.py with render_mode_selector() -> str",
        "Add mode selector: 'LLM Testing' | 'Agent Testing' using st.radio in sidebar",
        "Store mode in st.session_state['testing_mode']",
        "Agent mode shows: agent config panel, tool registration form, memory config",
        "Agent mode displays: OWASP coverage (TRC-016), timeline (TRC-017), tool chain (TRC-018)",
        "LLM mode preserves all existing functionality without changes",
        "Mode-specific help text using st.info/st.help",
        "Session state properly handles mode switch (clear agent-specific state on switch)",
        "Conditional rendering based on mode in main dashboard.py",
        "Mode persists across page refreshes via st.session_state"
      ],
      "priority": 20,
      "phaseId": 5,
      "passes": true,
      "dependsOn": ["TRC-016", "TRC-017", "TRC-018"],
      "notes": "Dashboard update for dual-mode support. LLM mode must remain fully functional.",
      "files": ["src/ui/dashboard.py", "src/ui/components/mode_selector.py"]
    },
    {
      "id": "TRC-020",
      "title": "Create LangChain integration adapter",
      "description": "As a developer, I need a LangChain adapter so that users can easily wrap LangChain agents.",
      "acceptanceCriteria": [
        "Create src/integrations/__init__.py (new package)",
        "Create src/integrations/langchain_adapter.py",
        "Class: LangChainAgentWrapper(InstrumentedAgent)",
        "Constructor accepts: agent (langchain.agents.AgentExecutor), config (AgentInstrumentationConfig)",
        "Automatically intercepts tool calls via LangChain callbacks (BaseCallbackHandler)",
        "Create RedCouncilCallbackHandler(BaseCallbackHandler) to capture on_tool_start, on_tool_end, on_tool_error",
        "Automatically monitors agent memory via agent.memory if present",
        "Class method: from_agent_executor(executor: AgentExecutor, config: Optional[AgentInstrumentationConfig] = None) -> LangChainAgentWrapper",
        "Handle both sync and async agent execution",
        "Documentation docstrings with usage examples",
        "Unit tests with mock LangChain agent (use unittest.mock, don't require langchain installed)"
      ],
      "priority": 21,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-003", "TRC-004", "TRC-005"],
      "notes": "LangChain is the most common agent framework. langchain is optional dependency.",
      "files": ["src/integrations/__init__.py", "src/integrations/langchain_adapter.py", "tests/integrations/test_langchain.py"]
    },
    {
      "id": "TRC-021",
      "title": "Create LangGraph integration adapter",
      "description": "As a developer, I need a LangGraph adapter so that users can wrap LangGraph workflows.",
      "acceptanceCriteria": [
        "Create src/integrations/langgraph_adapter.py",
        "Class: LangGraphAgentWrapper(InstrumentedAgent)",
        "Constructor accepts: graph (langgraph.graph.StateGraph or CompiledGraph), config (AgentInstrumentationConfig)",
        "Intercepts node executions as tool calls via graph instrumentation",
        "Monitors graph state as memory (capture state dict on each transition)",
        "Tracks state transitions as ActionRecords",
        "Method: wrap_node(node_name: str, node_func: Callable) -> Callable for manual node wrapping",
        "Class method: from_state_graph(graph: StateGraph, config: Optional[AgentInstrumentationConfig] = None) -> LangGraphAgentWrapper",
        "Documentation docstrings with usage examples",
        "Unit tests with mock LangGraph (use unittest.mock, don't require langgraph installed)"
      ],
      "priority": 22,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-003", "TRC-004", "TRC-005"],
      "notes": "LangGraph for stateful agent workflows. langgraph is optional dependency.",
      "files": ["src/integrations/langgraph_adapter.py", "tests/integrations/test_langgraph.py"]
    },
    {
      "id": "TRC-022",
      "title": "Create MCP protocol integration",
      "description": "As a developer, I need MCP protocol support so that users can test MCP-based agents.",
      "acceptanceCriteria": [
        "Create src/integrations/mcp_adapter.py",
        "Class: MCPAgentWrapper(InstrumentedAgent)",
        "Constructor accepts: client (mcp.Client or similar), config (AgentInstrumentationConfig)",
        "Intercepts MCP tool calls via client instrumentation",
        "Monitors MCP resource access (resources/read, resources/list)",
        "Tracks MCP prompts as memory operations",
        "Support MCP-over-stdio: wrap subprocess communication",
        "Support MCP-over-HTTP: wrap HTTP client calls",
        "Class method: from_stdio_server(command: List[str], config: Optional[AgentInstrumentationConfig] = None) -> MCPAgentWrapper",
        "Class method: from_http_server(url: str, config: Optional[AgentInstrumentationConfig] = None) -> MCPAgentWrapper",
        "Documentation docstrings with MCP server examples",
        "Unit tests with mock MCP client (use unittest.mock, don't require mcp installed)"
      ],
      "priority": 23,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-003", "TRC-004", "TRC-005"],
      "notes": "MCP is emerging protocol for agent tools. mcp is optional dependency.",
      "files": ["src/integrations/mcp_adapter.py", "tests/integrations/test_mcp.py"]
    },
    {
      "id": "TRC-023",
      "title": "Add agent orchestration mode to LangGraph arena",
      "description": "As a developer, I need to extend the arena orchestrator to handle agent testing so that the attack/judge/defend loop works with agents.",
      "acceptanceCriteria": [
        "Update src/orchestrator/state.py with AgentArenaState class",
        "AgentArenaState EXTENDS ArenaState (inheritance) - not replaces",
        "Add fields: instrumented_agent (Optional[InstrumentedAgent]), agent_events (List[AgentEvent]), owasp_scores (Optional[AgentJudgeScore]), testing_mode ('llm' | 'agent')",
        "Add field: agent_config (Optional[AgentInstrumentationConfig])",
        "Update src/orchestrator/graph.py to support agent mode",
        "Add mode check at graph entry: if state.testing_mode == 'agent' route to agent nodes",
        "Node: INSTRUMENT - wraps user agent with InstrumentedAgent if not already wrapped",
        "Node: AGENT_ATTACK - runs attacks and captures agent_events",
        "Node: AGENT_JUDGE - uses AgentJudge to evaluate agent_events, stores in owasp_scores",
        "Existing nodes (ATTACKING, JUDGING, DEFENDING, VERIFYING) remain for LLM mode",
        "Maintain backward compatibility: existing LLM-only tests must pass",
        "State serialization: instrumented_agent serialized as None (recreated on load)",
        "Integration tests for agent arena flow covering mode switch"
      ],
      "priority": 24,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-003", "TRC-008"],
      "notes": "Extend orchestrator for agent mode. AgentArenaState extends ArenaState - backward compatible.",
      "files": ["src/orchestrator/state.py", "src/orchestrator/graph.py", "tests/orchestrator/test_agent_arena.py"]
    },
    {
      "id": "TRC-024",
      "title": "Create agent defender for hardening recommendations",
      "description": "As a developer, I need an agent defender that generates agent-specific hardening so that users get remediation guidance.",
      "acceptanceCriteria": [
        "Create src/agents/agent_defender.py",
        "Class AgentDefender (composition with existing Defender pattern)",
        "Constructor: AgentDefender(llm_client: GeminiClient)",
        "Method: generate_hardening(score: AgentJudgeScore) -> AgentHardeningPlan",
        "Generates tool-level access controls based on tool_abuse_score",
        "Generates memory isolation recommendations based on memory_safety_score",
        "Generates guardrail configurations based on owasp_violations",
        "OWASP-specific remediation for each detected violation",
        "Method: generate_hardening_prompt(score: AgentJudgeScore) -> str for LLM-based generation",
        "Uses GeminiClient for LLM-powered recommendations (same pattern as defender.py)",
        "Fallback to rule-based hardening if LLM unavailable",
        "Unit tests for hardening generation covering all OWASP categories"
      ],
      "priority": 25,
      "phaseId": 4,
      "passes": true,
      "dependsOn": ["TRC-009", "TRC-014"],
      "notes": "Agent-specific defender for remediation. Uses AgentHardeningPlan from TRC-014.",
      "files": ["src/agents/agent_defender.py", "tests/agents/test_agent_defender.py"]
    },
    {
      "id": "TRC-025",
      "title": "Add API endpoints for agent testing mode",
      "description": "As a developer, I need API endpoints for agent testing so that users can programmatically test agents.",
      "acceptanceCriteria": [
        "Create src/api/agent_routes.py with FastAPI router",
        "Add POST /api/v1/agent/session endpoint to create agent testing session, returns session_id",
        "Add POST /api/v1/agent/session/{session_id}/events endpoint to submit agent events",
        "Add POST /api/v1/agent/session/{session_id}/evaluate endpoint to run agent evaluation",
        "Add GET /api/v1/agent/session/{session_id}/events endpoint to retrieve events",
        "Add GET /api/v1/agent/session/{session_id}/score endpoint to get AgentJudgeScore",
        "Add GET /api/v1/agent/session/{session_id}/report endpoint to get AgentSecurityReport",
        "Add DELETE /api/v1/agent/session/{session_id} endpoint to cleanup session",
        "Include router in main.py: app.include_router(agent_router, prefix='/api/v1/agent')",
        "OpenAPI schema updates with request/response models",
        "Rate limiting on POST endpoints (same pattern as existing routes)",
        "Unit tests for all endpoints using FastAPI TestClient"
      ],
      "priority": 26,
      "phaseId": 5,
      "passes": true,
      "dependsOn": ["TRC-008", "TRC-015"],
      "notes": "API endpoints for programmatic access. Session-based for stateful agent testing.",
      "files": ["src/api/agent_routes.py", "src/api/main.py", "tests/api/test_agent_routes.py"]
    },
    {
      "id": "TRC-026",
      "title": "Update documentation for agent testing",
      "description": "As a developer, I need documentation for the agent testing feature so that users know how to use it.",
      "acceptanceCriteria": [
        "Update README.md with Agent Testing section after existing content",
        "Create docs/agent-testing-guide.md with comprehensive guide",
        "Document InstrumentedAgent usage with code examples",
        "Document framework integrations (LangChain, LangGraph, MCP) with examples",
        "Document OWASP Agentic Top 10 coverage and what each category tests",
        "Document API endpoints with curl examples",
        "Create examples/agent_testing/ directory",
        "Create examples/agent_testing/basic_test.py - minimal example",
        "Create examples/agent_testing/langchain_example.py - LangChain integration",
        "Create examples/agent_testing/custom_agent.py - custom agent wrapping",
        "Update API docs (if OpenAPI/Swagger) with new endpoints"
      ],
      "priority": 27,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-020", "TRC-021", "TRC-022", "TRC-025"],
      "notes": "Documentation for new features. Examples are critical for adoption.",
      "files": ["README.md", "docs/agent-testing-guide.md", "examples/agent_testing/basic_test.py", "examples/agent_testing/langchain_example.py", "examples/agent_testing/custom_agent.py"]
    },
    {
      "id": "TRC-027",
      "title": "Create end-to-end integration test for agent testing",
      "description": "As a developer, I need E2E tests for the complete agent testing flow so that we verify everything works together.",
      "acceptanceCriteria": [
        "Create tests/e2e/test_agent_flow.py",
        "Test: wrap mock agent -> run attacks -> get score -> generate report (full flow)",
        "Test: LangChain integration E2E with mock LangChain agent",
        "Test: API endpoint flow E2E (create session -> submit events -> evaluate -> get report)",
        "Test: UI mode switch renders correct components (use streamlit testing utilities)",
        "Test: Agent arena orchestration completes successfully",
        "All tests pass in CI/CD (GitHub Actions)",
        "Tests use fixtures for common setup (conftest.py)",
        "Tests are isolated and can run in parallel",
        "Coverage for E2E tests contributes to overall 75%+ target"
      ],
      "priority": 28,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-023", "TRC-025", "TRC-019"],
      "notes": "E2E tests verify complete flow. Run after all components integrated.",
      "files": ["tests/e2e/test_agent_flow.py", "tests/e2e/test_langchain_e2e.py", "tests/e2e/conftest.py"]
    },
    {
      "id": "TRC-028",
      "title": "Add performance validation and benchmarks",
      "description": "As a developer, I need performance tests to validate sub-30s execution target for typical agent tests.",
      "acceptanceCriteria": [
        "Create tests/performance/test_agent_performance.py",
        "Benchmark: InstrumentedAgent wrap overhead < 5ms per event",
        "Benchmark: AgentJudge evaluation < 10s for 1000 events",
        "Benchmark: Full agent test flow < 30s for typical agent (50 tool calls, 100 events)",
        "Benchmark: ChromaDB agent_attacks retrieval < 500ms",
        "Use pytest-benchmark for consistent measurements",
        "Add performance CI job that fails if benchmarks regress >20%",
        "Document baseline performance in metadata.successMetrics",
        "Profile memory usage - ensure < 500MB for typical test"
      ],
      "priority": 29,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-027"],
      "notes": "Performance validation ensures sub-30s target from success metrics.",
      "files": ["tests/performance/test_agent_performance.py", "tests/performance/conftest.py"]
    },
    {
      "id": "TRC-029",
      "title": "Pin framework dependencies and create optional extras",
      "description": "As a developer, I need pinned versions of framework dependencies to ensure stability.",
      "acceptanceCriteria": [
        "Update pyproject.toml with optional dependency groups",
        "Create [project.optional-dependencies] section",
        "langchain extra: langchain>=0.1.0,<0.3.0, langchain-core>=0.1.0,<0.3.0",
        "langgraph extra: langgraph>=0.0.20,<0.1.0",
        "mcp extra: mcp>=0.1.0,<1.0.0 (or appropriate version)",
        "all-frameworks extra: combines langchain, langgraph, mcp",
        "Add streamlit-agraph>=0.0.45 to main dependencies for TRC-018",
        "Add pytest-benchmark to dev dependencies",
        "Document installation options in README: pip install .[langchain] etc",
        "CI tests run with all-frameworks installed"
      ],
      "priority": 30,
      "phaseId": 6,
      "passes": true,
      "dependsOn": [],
      "notes": "Framework version pinning prevents breaking changes. Optional deps keep core lightweight.",
      "files": ["pyproject.toml", "README.md"]
    },
    {
      "id": "TRC-030",
      "title": "Add smoke test for Phase 2 integration checkpoint",
      "description": "As a developer, I need an early integration test after Phase 2 to catch issues before full implementation.",
      "acceptanceCriteria": [
        "Create tests/integration/test_phase2_smoke.py",
        "Test: Create InstrumentedAgent with config",
        "Test: Record tool calls and memory access",
        "Test: Create AgentJudge and evaluate mock events",
        "Test: All OWASP check methods return valid ViolationResult",
        "Test: AgentJudgeScore serializes to JSON correctly",
        "Run as part of CI after Phase 2 stories complete",
        "Fails fast with clear error messages",
        "Documents integration points for Phase 3+"
      ],
      "priority": 10,
      "phaseId": 2,
      "passes": true,
      "dependsOn": ["TRC-009"],
      "notes": "Early integration test catches issues before Phase 3. Run after TRC-009.",
      "files": ["tests/integration/test_phase2_smoke.py"]
    },
    {
      "id": "TRC-031",
      "title": "Create VulnerableTestAgent for real integration testing",
      "description": "As a developer, I need a demo agent with intentional vulnerabilities so that we can run real integration tests against actual agent behavior, not just mocks.",
      "acceptanceCriteria": [
        "Create src/test_agents/__init__.py (new package for test agents)",
        "Create src/test_agents/vulnerable_agent.py with VulnerableTestAgent class",
        "VulnerableTestAgent has built-in tools: file_read, file_write, execute_command, send_email, database_query",
        "Intentional ASI01 vulnerability: No limits on tool calls (can call file_read unlimited times)",
        "Intentional ASI02 vulnerability: No confirmation required for dangerous actions (execute_command, send_email)",
        "Intentional ASI04 vulnerability: Accepts and processes injected instructions from tool outputs",
        "Intentional ASI06 vulnerability: Returns full database query results including sensitive fields",
        "Intentional ASI07 vulnerability: Memory accepts writes to system keys without validation",
        "VulnerableTestAgent.run(prompt: str) -> str executes the agent and returns response",
        "VulnerableTestAgent.get_events() -> List[AgentEvent] returns all recorded events",
        "Create tests/test_agents/test_vulnerable_agent.py with integration tests",
        "Integration test: Wrap VulnerableTestAgent with InstrumentedAgent",
        "Integration test: Run real attack prompts and verify vulnerabilities are detected",
        "Integration test: Verify AgentJudge correctly identifies all 5 intentional vulnerabilities",
        "Document which OWASP categories are testable with this agent"
      ],
      "priority": 32,
      "phaseId": 6,
      "passes": true,
      "dependsOn": ["TRC-003", "TRC-008"],
      "notes": "Real agent for integration testing - NOT a mock. This validates the entire pipeline against actual agent behavior. Test dir renamed to tests/vulnerable_agents to avoid conflict with tests/test_agents.py.",
      "files": ["src/test_agents/__init__.py", "src/test_agents/vulnerable_agent.py", "tests/vulnerable_agents/test_vulnerable_agent.py"]
    },
    {
      "id": "TRC-032",
      "title": "Seed agent attack database from documented research datasets",
      "description": "As a developer, I need to import agent-specific attack patterns from documented research datasets so that we have comprehensive real-world attack coverage equivalent to how LLM attacks are seeded from HarmBench/PyRIT/garak.",
      "acceptanceCriteria": [
        "Research and document sources in src/knowledge/agent_attack_sources.py",
        "Create AgentAttackSource enum: AGENTDOJO, ASB, INJECAGENT, TOOLEMU, RJUDGE, MCPTOX, HARMBENCH, GARAK, CUSTOM",
        "Extend AgentAttackTemplate with source (AgentAttackSource), source_id (str), agent_layer (str), real_world_tested (bool)",
        "Priority 0 integrations (REQUIRED):",
        "  - AgentDojo: Parse 629 test cases from ethz-spylab/agentdojo (Python classes)",
        "  - Agent Security Bench: Parse 400+ attack/defense pairs (84% success rate)",
        "  - InjecAgent: Parse 1,054 indirect injection payloads (UIUC)",
        "  - HarmBench: Parse 510 behaviors (already partially wired)",
        "Priority 1 integrations (RECOMMENDED):",
        "  - ToolEmu: Parse 144 tool-use safety test cases",
        "  - R-Judge: Parse 569 risk scenario interactions",
        "  - MCPTox: Parse 45+ real MCP server attack patterns",
        "  - garak: Extract probe plugins (1000+ payloads)",
        "  - MCP Security Docs: 7 documented attack patterns",
        "  - LangChain CVEs: CVE-2025-68664 serialization attacks",
        "Create seed function for each source: seed_from_<source>(kb, path) -> int",
        "Map each dataset's categories to OWASP Agentic Top 10 (ASI01-ASI10)",
        "Total minimum 500 agent attack templates seeded (from 3,500+ potential)",
        "Create CLI command: python -m src.knowledge.seed_agents --source <name> --path <path>",
        "Integration test: Seed from test fixtures and verify retrieval by OWASP category",
        "Document data format requirements and download instructions in docs/agent-attack-data.md"
      ],
      "priority": 33,
      "phaseId": 3,
      "passes": true,
      "dependsOn": ["TRC-010"],
      "notes": "Seeds real attack data equivalent to seed_data.py for LLM attacks. Sources: AgentDojo, InjecAgent, ToolEmu, R-Judge, MCPTox.",
      "files": ["src/knowledge/agent_attack_sources.py", "src/knowledge/agent_seed_data.py", "docs/agent-attack-data.md", "tests/knowledge/test_agent_attack_sources.py"]
    },
    {
      "id": "TRC-033",
      "title": "Wire Run Evaluation button to AgentJudge backend",
      "description": "As a user, I need the 'Run Evaluation' button to execute OWASP evaluation on captured events so that I can assess my agent's security posture.",
      "acceptanceCriteria": [
        "Button callback invokes AgentJudge.evaluate_agent_async() with session events",
        "Loading spinner displays during evaluation (use st.spinner)",
        "Results stored in st.session_state[AGENT_SCORE_KEY]",
        "OWASP Coverage tab auto-refreshes with evaluation results",
        "Error handling displays user-friendly message on failure",
        "Button disabled while evaluation is in progress",
        "Success toast notification when evaluation completes"
      ],
      "priority": 1,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-019"],
      "notes": "This is the critical wiring to connect the UI to the backend evaluation. AgentJudge and AgentJudgeConfig already exist.",
      "files": ["src/ui/dashboard.py", "src/ui/components/mode_selector.py"]
    },
    {
      "id": "TRC-034",
      "title": "Wire Generate Report button to AgentReportGenerator",
      "description": "As a user, I need the 'Generate Report' button to create a downloadable security report so that I can share findings with my team.",
      "acceptanceCriteria": [
        "Button callback invokes AgentReportGenerator.generate() with score and events",
        "Report rendered to markdown via report.to_markdown()",
        "Download button appears with report as .md file",
        "JSON export option available via report.model_dump(mode='json')",
        "Report viewer modal/expander shows formatted report preview",
        "Button disabled if no score available",
        "Error handling for report generation failures"
      ],
      "priority": 2,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-033"],
      "notes": "AgentReportGenerator and templates already exist. Need to wire UI to call generate() and render().",
      "files": ["src/ui/dashboard.py", "src/ui/components/report_viewer.py"]
    },
    {
      "id": "TRC-035",
      "title": "Implement Demo Mode with VulnerableTestAgent",
      "description": "As a new user, I need a 'Load Demo' button that populates the dashboard with sample data so that I can explore the platform without setting up my own agent.",
      "acceptanceCriteria": [
        "Add 'Load Demo' button in Agent Testing mode sidebar",
        "Button creates VulnerableTestAgent instance and runs sample attack prompts",
        "Pre-recorded events from demo run populate st.session_state[AGENT_EVENTS_KEY]",
        "Timeline, Tool Chain tabs immediately show populated data",
        "Demo mode indicator shown in header/sidebar",
        "Clear Demo button to reset to empty state",
        "Demo includes representative events: tool calls, memory access, divergence",
        "Demo attacks trigger at least 3 OWASP violations (ASI01, ASI06, ASI07)"
      ],
      "priority": 3,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-031", "TRC-033"],
      "notes": "VulnerableTestAgent already has intentional vulnerabilities for ASI01, ASI02, ASI04, ASI06, ASI07. Generate demo events by running standard attack prompts against it.",
      "files": ["src/ui/dashboard.py", "src/ui/components/demo_loader.py", "src/test_agents/vulnerable_agent.py"]
    },
    {
      "id": "TRC-036",
      "title": "Create SDK Connection Panel with code snippets",
      "description": "As a developer, I need an SDK connection panel showing code snippets for my framework so that I can instrument my agent to send events to the dashboard.",
      "acceptanceCriteria": [
        "New 'SDK Integration' tab in Agent Testing mode",
        "Framework selector: LangChain, LangGraph, MCP, Custom",
        "Framework-specific code snippet displayed with syntax highlighting",
        "Copy-to-clipboard button for code snippet",
        "Session webhook URL displayed: /api/v1/agent/session/{session_id}/events",
        "Auto-generate session ID on panel load if none exists",
        "Link to full documentation for each framework",
        "Code snippets include authentication header example"
      ],
      "priority": 4,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-020", "TRC-021", "TRC-022", "TRC-025"],
      "notes": "Framework adapters exist in src/integrations/. Generate snippets showing how to wrap agent and POST events to webhook URL.",
      "files": ["src/ui/components/sdk_connection.py", "src/ui/dashboard.py"]
    },
    {
      "id": "TRC-037",
      "title": "Create Remote Agent Configuration panel",
      "description": "As a security tester, I need to configure a remote agent endpoint so that I can run attacks against any HTTP-accessible agent without code changes.",
      "acceptanceCriteria": [
        "New 'Remote Agent' tab/section in Agent Testing mode",
        "Agent endpoint URL input with validation",
        "Auth configuration: Bearer token, API key header, or None",
        "Request format selector: OpenAI-compatible, custom JSON template",
        "Response format selector: text, JSON path extraction",
        "Test connection button with status indicator",
        "Save configuration to session state",
        "Configuration persists across page refreshes"
      ],
      "priority": 5,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-019"],
      "notes": "Similar to existing LLM model configuration pattern. Remote agent acts as target for attack campaigns.",
      "files": ["src/ui/components/remote_agent_config.py", "src/ui/dashboard.py", "tests/ui/test_remote_agent_config.py"]
    },
    {
      "id": "TRC-038",
      "title": "Create Attack Template Selector component",
      "description": "As a security tester, I need to select which attack templates to run so that I can focus testing on specific OWASP categories or agent capabilities.",
      "acceptanceCriteria": [
        "New 'Attack Templates' panel in Agent Testing mode",
        "Filter by OWASP category (ASI01-ASI10 checkboxes)",
        "Filter by capability: requires_tool_access, requires_memory_access",
        "Display template count per filter combination",
        "Select All / Deselect All buttons",
        "Preview selected templates in expandable list",
        "Show template details: prompt preview, expected behavior, severity",
        "Selected templates stored in session state for campaign execution"
      ],
      "priority": 6,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-010", "TRC-011", "TRC-012", "TRC-013"],
      "notes": "AgentAttackKnowledgeBase provides get_attacks_for_owasp() and get_attacks_by_capability() methods. 27+ templates available.",
      "files": ["src/ui/components/attack_selector.py", "src/ui/dashboard.py"]
    },
    {
      "id": "TRC-039",
      "title": "Implement Attack Campaign Orchestration UI",
      "description": "As a security tester, I need to launch and monitor an attack campaign so that I can systematically test a remote agent against selected templates.",
      "acceptanceCriteria": [
        "Start Campaign button launches selected attacks against configured remote agent",
        "Campaign progress bar shows attacks completed / total",
        "Real-time status updates as each attack executes",
        "Pause/Resume campaign controls",
        "Cancel campaign with graceful cleanup",
        "Campaign results summary: attacks run, responses captured, errors",
        "Auto-convert agent responses to AgentEvent format",
        "Events automatically populate Timeline and Tool Chain tabs",
        "Campaign completion triggers notification"
      ],
      "priority": 7,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-037", "TRC-038"],
      "notes": "Orchestrates sending attack templates to remote agent endpoint, capturing responses, and converting to events for evaluation.",
      "files": ["src/ui/components/campaign_runner.py", "src/ui/dashboard.py", "src/orchestrator/agent_campaign.py"]
    },
    {
      "id": "TRC-040",
      "title": "Implement real-time event streaming display",
      "description": "As a developer using SDK mode, I need to see events appear in real-time as my instrumented agent sends them so that I can verify my integration is working.",
      "acceptanceCriteria": [
        "Events appear in Timeline tab within 1 second of submission to API",
        "New event indicator/badge shows count of recent events",
        "Auto-scroll option to follow new events",
        "Event rate indicator (events/second)",
        "Connection status indicator for webhook endpoint",
        "Pause/Resume streaming toggle",
        "Buffer indicator showing pending events",
        "Works with both SDK webhook and polling approaches"
      ],
      "priority": 8,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-036", "TRC-017"],
      "notes": "Streamlit has limited real-time capabilities. Use st.experimental_rerun with polling or streamlit-server-state for shared state.",
      "files": ["src/ui/components/event_stream.py", "src/ui/providers/polling.py", "src/ui/dashboard.py"]
    },
    {
      "id": "TRC-041",
      "title": "Create Report Viewer with export options",
      "description": "As a user, I need a full-featured report viewer so that I can explore findings in detail and export in multiple formats.",
      "acceptanceCriteria": [
        "Report viewer modal/page shows full AgentSecurityReport",
        "Sections: Summary, OWASP Coverage, Tool Analysis, Memory Analysis, Divergence Analysis, Recommendations",
        "Export formats: Markdown (.md), JSON (.json), PDF (if reportlab available)",
        "Print-friendly view option",
        "Copy individual sections to clipboard",
        "Link to specific findings via URL anchors",
        "Historical reports list (if multiple evaluations run)",
        "Compare reports feature (diff between two evaluations)"
      ],
      "priority": 9,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-034"],
      "notes": "Extends basic report download with rich viewing experience. Report template already exists in src/reports/templates/report.md.j2.",
      "files": ["src/ui/components/report_viewer.py", "src/ui/pages/report.py"]
    },
    {
      "id": "TRC-042",
      "title": "Create onboarding flow and empty states",
      "description": "As a new user, I need clear guidance on how to get started so that I can quickly understand the platform and begin testing.",
      "acceptanceCriteria": [
        "Empty state for Timeline tab: illustration + 'No events yet' + action buttons",
        "Empty state for OWASP Coverage: 'Run evaluation to see results'",
        "Empty state for Tool Chain: 'No tool calls captured'",
        "First-time user welcome modal with mode selection",
        "Quick start guide for each mode (Demo, SDK, Remote)",
        "Contextual help tooltips on key UI elements",
        "Link to documentation from empty states",
        "Progress indicator for getting started checklist"
      ],
      "priority": 10,
      "phaseId": 7,
      "passes": true,
      "dependsOn": ["TRC-019"],
      "notes": "Improve user onboarding with clear empty states and guidance. Reduces confusion for new users.",
      "files": ["src/ui/components/empty_states.py", "src/ui/components/onboarding.py", "src/ui/dashboard.py"]
    },
    {
      "id": "TRC-043",
      "title": "Implement session management UI",
      "description": "As a user, I need to manage multiple testing sessions so that I can organize different test runs and compare results.",
      "acceptanceCriteria": [
        "Session list sidebar showing active/completed sessions",
        "Create new session button with optional name/description",
        "Switch between sessions without losing data",
        "Delete session with confirmation dialog",
        "Session metadata display: created time, event count, evaluation status",
        "Export session data (events + score + report)",
        "Import session from JSON file",
        "Session naming and tagging",
        "Auto-cleanup of old sessions (configurable retention)"
      ],
      "priority": 11,
      "phaseId": 7,
      "passes": false,
      "dependsOn": ["TRC-025"],
      "notes": "API already supports session CRUD operations. Need UI to expose these capabilities.",
      "files": ["src/ui/components/session_manager.py", "src/ui/dashboard.py"]
    },
    {
      "id": "TRC-044",
      "title": "Add keyboard shortcuts and power user features",
      "description": "As a power user, I need keyboard shortcuts and advanced features so that I can work efficiently without excessive clicking.",
      "acceptanceCriteria": [
        "Keyboard shortcut panel (? key to show)",
        "Ctrl+E: Run Evaluation",
        "Ctrl+R: Generate Report",
        "Ctrl+D: Load Demo",
        "Ctrl+N: New Session",
        "Tab navigation between main panels",
        "Command palette (Ctrl+K) for quick actions",
        "Dark mode toggle",
        "Density toggle (compact/comfortable)",
        "Shortcuts work when focus is in main content area"
      ],
      "priority": 12,
      "phaseId": 7,
      "passes": false,
      "dependsOn": ["TRC-019"],
      "notes": "Streamlit has limited keyboard shortcut support. May require custom JavaScript injection via st.components.v1.html.",
      "files": ["src/ui/components/shortcuts.py", "src/ui/dashboard.py"]
    }
  ],
  "metadata": {
    "version": "0.5.0",
    "codename": "Agent Security",
    "created": "2026-02-01",
    "updated": "2026-02-02",
    "estimatedDays": 40,
    "estimatedHours": 160,
    "epics": [
      {"name": "Agent Instrumentation SDK", "stories": ["TRC-001", "TRC-002", "TRC-003", "TRC-004", "TRC-005", "TRC-006"]},
      {"name": "Extended Judge for Agents", "stories": ["TRC-007", "TRC-008", "TRC-009", "TRC-030"]},
      {"name": "Agent Attack Templates", "stories": ["TRC-010", "TRC-011", "TRC-012", "TRC-013", "TRC-032"]},
      {"name": "Agent Security Reports", "stories": ["TRC-014", "TRC-015", "TRC-024"]},
      {"name": "UI Enhancements", "stories": ["TRC-016", "TRC-017", "TRC-018", "TRC-019", "TRC-025"]},
      {"name": "Framework Integrations", "stories": ["TRC-020", "TRC-021", "TRC-022", "TRC-023", "TRC-026", "TRC-027", "TRC-028", "TRC-029", "TRC-031"]},
      {"name": "UI/UX Completion", "stories": ["TRC-033", "TRC-034", "TRC-035", "TRC-036", "TRC-037", "TRC-038", "TRC-039", "TRC-040", "TRC-041", "TRC-042", "TRC-043", "TRC-044"]}
    ],
    "dependencies": {
      "external": {
        "required": ["sentence-transformers", "chromadb", "streamlit-agraph", "pytest-benchmark"],
        "optional": {
          "langchain": ["langchain>=0.1.0,<0.3.0", "langchain-core>=0.1.0,<0.3.0"],
          "langgraph": ["langgraph>=0.0.20,<0.1.0"],
          "mcp": ["mcp>=0.1.0,<1.0.0"]
        }
      },
      "internal": ["src/agents/judge.py", "src/agents/errors.py", "src/knowledge/attack_kb.py", "src/orchestrator/graph.py", "src/core/schemas.py"]
    },
    "risks": [
      {"risk": "Framework API changes", "mitigation": "Pin versions in pyproject.toml, abstract interfaces via adapters", "severity": "HIGH"},
      {"risk": "OWASP spec updates", "mitigation": "Modular enum design in TRC-001 allows updates without breaking changes", "severity": "MEDIUM"},
      {"risk": "Performance with many events", "mitigation": "Event sampling (TRC-003), pagination (TRC-017), benchmarks (TRC-028)", "severity": "MEDIUM"},
      {"risk": "Streamlit UI limitations", "mitigation": "Graceful fallbacks in TRC-016, TRC-017, TRC-018", "severity": "LOW"},
      {"risk": "Integration complexity", "mitigation": "Smoke test (TRC-030) catches issues early, clear state extension in TRC-023", "severity": "HIGH"}
    ],
    "successMetrics": [
      "All 10 OWASP Agentic categories testable with detection criteria",
      "3+ framework integrations working (LangChain, LangGraph, MCP)",
      "Sub-30s test execution for typical agent (validated by TRC-028)",
      "75%+ test coverage maintained across all new code",
      "Zero breaking changes to existing LLM testing functionality",
      "Three working agent testing modes: Demo, SDK, Remote URL",
      "End-to-end user flow from mode selection to report download"
    ],
    "newPackages": [
      "src/integrations/__init__.py",
      "src/reports/__init__.py",
      "src/test_agents/__init__.py"
    ],
    "schemaDefinitions": {
      "TRC-002": ["AgentEvent (union)", "AgentInstrumentationConfig", "ToolCallEvent", "MemoryAccessEvent", "ActionRecord", "SpeechRecord", "DivergenceEvent"],
      "TRC-007": ["ViolationResult", "AgentJudgeScore"],
      "TRC-014": ["AgentSecurityReport", "AgentHardeningPlan", "ToolAccessControl", "MemoryPolicy", "GuardrailConfig", "ToolAnalysisSection", "MemoryAnalysisSection", "DivergenceAnalysisSection", "Recommendation", "RemediationStep"],
      "TRC-031": ["VulnerableTestAgent"],
      "TRC-032": ["AgentAttackSource (enum)"]
    },
    "attackDataSources": {
      "description": "Documented research datasets for seeding agent attack templates (TRC-032)",
      "priority0": [
        {"name": "AgentDojo", "repo": "ethz-spylab/agentdojo", "count": 629, "format": "Python classes", "owaspMapping": "ASI01-ASI10", "domains": ["banking", "slack", "travel", "workspace"]},
        {"name": "Agent Security Bench", "repo": "ASBench", "count": 400, "format": "attack/defense pairs", "owaspMapping": "ASI01-ASI10", "successRate": "84.30%"},
        {"name": "InjecAgent", "repo": "UIUC-Kang Lab", "count": 1054, "format": "indirect injection payloads", "owaspMapping": "ASI04, ASI08"},
        {"name": "HarmBench", "repo": "centerforaisafety/HarmBench", "count": 510, "format": "behaviors", "owaspMapping": "ASI01-ASI10"}
      ],
      "priority1": [
        {"name": "ToolEmu", "repo": "ryoungj/ToolEmu", "count": 144, "format": "tool-use safety test cases", "owaspMapping": "ASI01, ASI02, ASI03"},
        {"name": "R-Judge", "repo": "Lordog/R-Judge", "count": 569, "format": "risk scenario interactions", "owaspMapping": "ASI01-ASI10"},
        {"name": "MCPTox", "repo": "arXiv:2508.14925", "count": 45, "format": "MCP server attacks", "owaspMapping": "ASI03, ASI04, ASI05"},
        {"name": "SafeToolBench", "repo": "arXiv:2509.07315", "count": 16, "format": "domain attack vectors", "owaspMapping": "ASI01-ASI06"},
        {"name": "ToolHijacker", "repo": "arXiv:2504.19793", "count": 50, "format": "tool description injection", "owaspMapping": "ASI03, ASI04", "successRate": "96.7%"},
        {"name": "garak", "repo": "NVIDIA/garak", "count": 1000, "format": "probe plugins", "owaspMapping": "ASI01-ASI10"},
        {"name": "MCP Security Docs", "repo": "modelcontextprotocol.io", "count": 7, "format": "attack patterns", "owaspMapping": "ASI03, ASI04, ASI05"},
        {"name": "LangChain CVEs", "repo": "CVE-2025-68664", "count": 3, "format": "real exploits", "owaspMapping": "ASI06, ASI07"}
      ],
      "priority2": [
        {"name": "CVE-Bench", "repo": "uiuc-kang-lab/cve-bench", "count": 40, "format": "real CVE PoCs", "owaspMapping": "ASI01, ASI03, ASI05"},
        {"name": "GPTFUZZER", "repo": "sherdencooper/GPTFuzz", "count": 200, "format": "mutated jailbreaks", "owaspMapping": "ASI08, ASI09"},
        {"name": "AgentHarm", "repo": "OSU-NLP-Group/AgentSafety", "count": 11, "format": "harm categories", "owaspMapping": "ASI01-ASI10"}
      ],
      "totalPotentialAttacks": 3500,
      "targetSeeded": 500,
      "alreadyWired": ["PyRIT (165 templates)"]
    }
  }
}